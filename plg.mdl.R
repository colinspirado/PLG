#Function to create lavaan model syntax for a parallel latent growth model
	#Assumes data is in wide form with column names indicating test (sequential ltrs) and time (integers) in the form: A.1,A.2,...,B.1,...
	#Model call can be to cfa or sem
#Required arguments are:
	#tests: either a number in 2:26 indicating the number of (sequentially lettered) tests, or a character vector specifying the test letter names
	#t: a numeric vector specifying the measurment times
#Optional arguments are:
	#learning: can be specified as a vector of test letter names or as TRUE if all tests are to be modeled as having learning effects
	#covariates: a character vector containing the names of covariates on which intercepts and slopes are regressed
	#s0 specifies tests that are to be modeled as having slope variance = 0
plg.mdl<-function(tests,t,learning=NULL,covariates=NULL,s0=NULL)
{
#Define vector of test letter names
if(is.numeric(tests)){ltrs=LETTERS[1:tests]}else{ltrs=toupper(tests)}
n.test=length(ltrs)
if(is.logical(learning)){if(learning==T){learning=ltrs}else{learning=NULL}}
#Specify factor loadings for random intercepts
int=''
for(i in 1:n.test)
	{
	int=paste(int,paste('i.',ltrs[i],'=~',paste0(paste('1*',ltrs[i],'.',t,sep=''),collapse='+'),' \n ',sep=''),sep='')
	}
#Specify factor loadings for random slopes
slp=''
for(i in 1:n.test)
	{
	slp=paste(slp,paste('s.',ltrs[i],'=~',paste0(paste(t,'*',ltrs[i],'.',t,sep=''),collapse='+'),' \n ',sep=''),sep='')
	}
#Specify intercept (co)variances
icovar=''
for(i in 1:(n.test-1))
	{
	icovar=paste(icovar,paste('i.',ltrs[i],'~~',paste0(paste('i',ltrs[(i+1):n.test],sep='.'),collapse='+'),' \n ',sep=''),sep='')
	}
#Specify slope variances
svar=''
for(i in 1:n.test)
	{
	svar=paste(svar,paste('s.',ltrs[i],'~~',c('','0*')[ltrs[i]%in%s0+1],'s.',ltrs[i],' \n ',sep=''),sep='')
	}
#Specify slope covariances
ls1=ltrs[!ltrs%in%s0]
scov=''
if(length(ls1)>1){for(i in 1:(length(ls1)-1))
	{
	scov=paste(scov,paste('s.',ls1[i],'~~',paste0(paste('s',ls1[(i+1):length(ls1)],sep='.'),collapse='+'),' \n ',sep=''),sep='')
	}}
#Specify intercept-slope covariances
iscov=''
for(i in 1:n.test)
	{
	iscov=paste(iscov,paste('i.',ltrs[i],'~~',paste0(paste('s',ls1,sep='.'),collapse='+'),' \n ',sep=''),sep='')
	}
#Specify residual variance constraints
rvar=''
for(i in 1:n.test)
	{
	rvar=paste(rvar,paste(paste0(paste(ltrs[i],'.',t,'~~v.',ltrs[i],'*',ltrs[i],'.',t,sep=''),collapse=' \n '),' \n ',sep=''),sep='')
	}
#Specify within-occasion residual covariance constraints
rcov=''
for(i in 1:(n.test-1)){for(j in 1:length(t))
	{
	rcov=paste(rcov,paste(ltrs[i],'.',t[j],'~~',paste0(paste('c.',ltrs[i],ltrs[(i+1):n.test],'*',ltrs[(i+1):n.test],'.',t[j],sep=''),collapse='+'),' \n ',sep=''),sep='')
	}}
#Add in learning effects if !is.null(learning)
if(!is.null(learning)&is.null(covariates))
	{
	lfx=paste(paste(paste0(paste(learning,t[1],sep='.'),collapse='+'),'~1',sep=''),' \n ',sep='')
	}
#Add in regression models for random effects, and if applicable learning effects
if(is.null(covariates)){covariates=1}   #regression model for random effects only includes intercept if no covariates specified
lreg=paste(paste(paste(paste0(paste('i',ltrs,sep='.'),collapse='+'),paste0(paste('s',ltrs,sep='.'),collapse='+'),sep='+'),paste0(covariates,collapse='+'),sep='~'),' \n ',sep='')
if(!is.null(learning))
	{
	lfx=paste(paste(paste0(paste(learning,t[1],sep='.'),collapse='+'),'~',paste0(covariates,collapse='+'),sep=''),' \n ',sep='')
	}
#Add in observed variable intercept constraints
if(is.null(learning))
	{
	ovi=paste(paste0(paste(ltrs,rep(t,each=n.test),sep='.'),collapse='+'),'~0*1 \n ',sep='')
	}
if(!is.null(learning))
	{
	if(prod(learning==ltrs)==0){ovi=paste(paste0(paste(ltrs[!ltrs%in%learning],0,sep='.'),collapse='+'),'+',sep='')}else{ovi=''}
	ovi=paste(paste(ovi,paste0(paste(ltrs,rep(t[2:length(t)],each=n.test),sep='.'),collapse='+'),sep=''),'~0*1 \n ',sep='')
	}
#Construct and return output string
out=paste(int,slp,icovar,svar,scov,iscov,rvar,rcov,ovi,lreg,sep='')
if(!is.null(learning)){out=paste(out,lfx,sep='')}
return(out)
}


#Function to extract parameters from a lavaan fit with model syntax generated by plg.mdl
#Required arguments are:
	#fit: the lavaan model fit returned by cfa()
	#tests: see plg.mdl()
	#t: see plg.mdl()
#Optional arguments are:
	#learning: see plg.mdl()
	#covariates: see plg.mdl()
	#s0: see plg.mdl()
#The function returns a list with elements:
	#Sb: covariance matrix of random slopes
	#Se: covariance matrix of residual errors
	#s.beta: vector of mean slopes
	#Depending on optional arguments, the following modifications are possible
		#s.beta: if covariates are specified, s.beta is formatted as a matrix with rows corresponding to tests and columns corresponding to covariates
		#i.beta: if covariates are specified, i.beta (intercepts) is constructed analogous to s.beta
		#l.beta: if learning effects are specified, they are returned in l.beta, either as a vector (no covariates) or as a matrix (covariates)
plg.par<-function(fit,tests,t,learning=NULL,covariates=NULL,s0=NULL)
{
if(is.numeric(tests)){ltrs=LETTERS[1:tests]}else{ltrs=toupper(tests)}
n.test=length(ltrs)
if(is.logical(learning)){if(learning==T){learning=ltrs}else{learning=NULL}}
prefix=rep(ltrs,times=n.test)
	prefix[prefix>rep(ltrs,each=n.test)]=rep(ltrs,each=n.test)[prefix>rep(ltrs,each=n.test)]
suffix=rep(ltrs,each=n.test)
	suffix[suffix<rep(ltrs,times=n.test)]=rep(ltrs,times=n.test)[suffix<rep(ltrs,times=n.test)]
Se=Sb=rep(NA,n.test^2)
#if(!is.null)
#Extract and format Sb
Sb[prefix%in%s0|suffix%in%s0]=0
Sb[is.na(Sb)]=coef(fit)[paste('s.',prefix[is.na(Sb)],'~~','s.',suffix[is.na(Sb)],sep='')]
Sb=matrix(Sb,nrow=n.test,ncol=n.test)
#Extract and format Se
Se[prefix==suffix]=coef(fit)[paste('v',ltrs,sep='.')]
Se[is.na(Se)]=coef(fit)[paste('c.',prefix[is.na(Se)],suffix[is.na(Se)],sep='')]
Se=matrix(Se,nrow=n.test,ncol=n.test)
#Extract s.beta
s.beta=coef(fit)[paste('s.',ltrs,'~1',sep='')]
#Extract l.beta
if(!is.null(learning)){l.beta=coef(fit)[paste(ltrs,'.',t[1],'~1',sep='')]}
#Extract and format covariate effects on latent variables
if(!is.null(covariates))
	{
	i.beta=coef(fit)[paste('i.',ltrs,'~1',sep='')]
	for(c in 1:length(covariates))
		{
		s.beta=cbind(s.beta,coef(fit)[paste('s.',ltrs,'~',covariates[c],sep='')])
		i.beta=cbind(i.beta,coef(fit)[paste('i.',ltrs,'~',covariates[c],sep='')])
		if(!is.null(learning)){l.beta=cbind(l.beta,coef(fit)[paste(ltrs,'.',t[1],'~',covariates[c],sep='')])}
		}
	colnames(s.beta)=colnames(i.beta)=covariates
	rownames(s.beta)=rownames(i.beta)=ltrs
	if(!is.null(learning)){colnames(l.beta)=covariates; rownames(l.beta)=ltrs; l.beta[is.na(l.beta)]=0}
	}
#Construct and return output list
out=list('Sb'=Sb,'Se'=Se,'s.beta'=s.beta)
if(!is.null(covariates)){out$i.beta=i.beta}
if(!is.null(learning)){out$l.beta=l.beta}
return(out)
}


#Function to generate syntax for an unstructured model fit
#May be elaborated to allow for covariates, but for now the purpose is to permit some model comparison between unstructured and (p)lg fits
#Can be used for a single test with at least two observations
#Required arguments are:
	#tests: see plg.mdl()
	#t: see plg.mdl()
uns.mdl<-function(tests,t)
{
if(is.numeric(tests)){ltrs=LETTERS[1:tests]}else{ltrs=toupper(tests)}
n.test=length(ltrs)
obset=paste(rep(ltrs,each=length(t)),rep(t,times=n.test),sep='.')
out=NULL
for(i in 1:(length(obset)-1))
	{
	out=paste(out,paste(obset[i],paste0(obset[(i+1):length(obset)],collapse='+'),sep='~~'),sep=' \n ')
	}
return(substr(out,4,nchar(out)))
}


#Function to generate syntax for a single variable latent growth model
#May be elaborated to allow for covariates, but for now the purpose is to permit some model comparison between lg and unstructured fits
#cfa() calls using syntax generated by lg.mdl() should specify orthogonal=T
#Required arguments are:
	#test: character string giving the name of the test
	#t: see plg.mdl()
#Optional arguments are:
	#learning: logical indicating whether a learning effect should be included in the model
	#s0: logical indicating whether slope variance should be set to 0
lg.mdl<-function(test,t,learning=F,s0=F)
{
#Specify factor loadings for random intercept
int=paste('i',paste0(paste('1*',test,'.',t,sep=''),collapse='+'),sep='=~')
#Specify factor loadings for random slope
slp=paste('s',paste0(paste(t,'*',test,'.',t,sep=''),collapse='+'),sep='=~')
#Specify slope variance or intercept-slope covariance according to value of s0
if(!s0){scov='i~~s'}else{scov='s~~0*s'}
#Specify residual variance constraints
rvar=paste0(paste(test,'.',t,'~~v*',test,'.',t,sep=''),collapse=' \n ')
#Specify observed variable intercept contraints according to value of learning
ovi=paste(paste0(paste(test,t[(learning+1):length(t)],sep='.'),collapse='+'),'~0*1',sep='')
out=paste(int,slp,scov,rvar,ovi,sep=' \n ')
return(out)
}


#Function to create wide-form longitudinal data.frame for input to cfa()
#Performs rounding of time variable to desired precision
#Required arguments are:
	#data: long-form data frame containing all columns of interest
	#id: unique subject identifier, used in merging
	#t: character variable giving the name of the time variable
	#unit: numeric variable giving the desired precision in rounded values of t (e.g., to round to the nearest half-year specify unit=0.5)
	#tests: character vector containing the names of the tests
#Any columns not designated as id, t, or tests are treated as time-invariant covariates with values taken from baseline = min(t) after rounding
towide<-function(data,id,t,unit,tests)
{
library(tidyr)
#Format names
names(data)[names(data)%in%c(id,t,tests)]=c('id','t',LETTERS[1:length(tests)])
#Round t and declare as ordered variable
data$t=unit*round(data$t/unit)
	data=subset(data,!is.na(t))
tset=with(data,seq(from=min(t),to=max(t),by=unit))
#tset=sort(unique(data$t))
#Reclassify t as ordered for later use in spread
data$t=with(data,ordered(t,levels=seq(from=min(t),to=max(t),by=unit)))
#Initialize wide-form data.frame with id and covariate values at baseline
wide=subset(data,t%in%min(tset))
	wide=wide[!names(wide)%in%c('t',LETTERS)]
#Spread on test A and merge with wide
foo=subset(data,!is.na(A),c(id,t,A))
foo=spread(foo,t,A,drop=F)
	names(foo)=c('id',paste('A',tset,sep='.'))
	foo[,paste('A',tset,sep='.')]=lapply(foo[,paste('A',tset,sep='.')],as.numeric)
wide=merge(wide,foo,all=T)
#Repeat with other tests and merge results if length(tests)>1
if(length(tests)>1){for(i in 2:length(tests))
	{
	foo=subset(data,!is.na(eval(as.name(LETTERS[i]))),c('id','t',LETTERS[i]))
		names(foo)[names(foo)==LETTERS[i]]='var'
	foo=spread(foo,t,var,drop=F)
		names(foo)=c('id',paste(LETTERS[i],tset,sep='.'))
		foo[,paste(LETTERS[i],tset,sep='.')]=lapply(foo[,paste(LETTERS[i],tset,sep='.')],as.numeric)
	wide=merge(wide,foo,all=T)
	}}
print(paste('The following columns had no data and have been excluded: ',paste0(names(wide)[colMeans(is.na(wide))==1],collapse=', '),sep=''))
wide=wide[,colMeans(is.na(wide))<1]
return(wide)
}

